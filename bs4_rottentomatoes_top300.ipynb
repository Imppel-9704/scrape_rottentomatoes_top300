{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imppel-9704/scrape_rottentomatoes_top300/blob/main/bs4_rottentomatoes_top300.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "rank = []\n",
        "movie = []\n",
        "link = []\n",
        "\n",
        "def call_bs4():\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "  response = requests.get(\"https://editorial.rottentomatoes.com/guide/best-movies-of-all-time/\",  headers=headers)\n",
        "  response.raise_for_status()\n",
        "  return BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "def scrape_table():\n",
        "  soup = call_bs4()\n",
        "  main = soup.find_all(\"table\", class_= \"aligncenter\")\n",
        "\n",
        "  for m in main:\n",
        "\n",
        "    order = m.find_all(\"td\", attrs={\"style\": \"width: 10%; height: 23px; text-align: center;\"})\n",
        "    rank.extend([o.text.strip() for o in order])\n",
        "\n",
        "    title = m.find_all(\"a\", class_= \"title\")\n",
        "    movie.extend([t.text.strip() for t in title])\n",
        "    link.extend([t.get(\"href\") for t in title])\n",
        "\n",
        "  data = {\n",
        "      r : {\"title\": m, \"link\": l} for r, m, l in zip(rank, movie, link)\n",
        "  }\n",
        "  return data\n",
        "\n",
        "def extract_from_data(data):\n",
        "  for rank, item in list(data.items()):\n",
        "    response = requests.get(item['link'])\n",
        "    if response.status_code != 200:\n",
        "      return None\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    details = soup.find_all(\"div\", class_= \"media-scorecard no-border\")\n",
        "\n",
        "    for d in details:\n",
        "      script = d.find('script', {'data-json': 'mediaScorecard', 'id': 'media-scorecard-json'})\n",
        "\n",
        "      if script: # check if script is not null\n",
        "        # Convert text to dictionary\n",
        "        data_dict = json.loads(script.text.strip())\n",
        "        # get audience score\n",
        "        audience_score = data_dict.get('audienceScore', {})\n",
        "        item['description'] = data_dict.get('description')\n",
        "        item['audience_like'] = audience_score.get('likedCount')\n",
        "        item['audience_notlike'] = audience_score.get('notLikedCount')\n",
        "        item['total_audience_review'] = audience_score.get('reviewCount')\n",
        "        item['audience_score'] = audience_score.get('score')\n",
        "        item['audience_sentiment'] = audience_score.get('sentiment')\n",
        "        item['audience_score_percent'] = audience_score.get('scorePercent')\n",
        "        # Get critics score\n",
        "        critics_score = data_dict.get('criticsScore', {})\n",
        "        item['critic_like'] = critics_score.get('likedCount')\n",
        "        item['critic_notlike'] = critics_score.get('notLikedCount')\n",
        "        item['total_critic_review'] = critics_score.get('reviewCount')\n",
        "        item['critic_score'] = critics_score.get('score')\n",
        "        item['critic_sentiment'] = critics_score.get('sentiment')\n",
        "        item['critic_score_percent'] = critics_score.get('scorePercent')\n",
        "    crews = soup.find('div', {'data-modulecastcrewmanager': 'container'})\n",
        "    if crews:\n",
        "      director = crews.find(\"p\", class_= \"name\")\n",
        "      item['director'] = director.text.strip() if director else \"\"\n",
        "\n",
        "    information = soup.find_all(\"div\", class_= \"media-hero-wrap\")\n",
        "    for inf in information:\n",
        "      text = inf.find_all(\"rt-text\", slot= \"metadataProp\")\n",
        "      item['metadata'] = [md.text for md in text]\n",
        "      allgenre = inf.find_all(\"rt-text\", slot= \"metadataGenre\")\n",
        "      item['genre'] = [g.text for g in allgenre]\n",
        "  return data\n",
        "\n",
        "def transform_data(data):\n",
        "  for key, item in data.items():\n",
        "    if \"metadata\" in item:\n",
        "      item['rate'], item['released date'], item['duration'] = ([\"\"] + item['metadata'])[-3:]\n",
        "      item['genre'] = ', '.join(item['genre'])\n",
        "      item.pop(\"metadata\")\n",
        "\n",
        "  df = pd.DataFrame.from_dict(data, orient='index').reset_index()\n",
        "  df.rename(columns={\"index\": \"no\"}, inplace=True)\n",
        "  return df\n",
        "\n",
        "def save_to_csv(df):\n",
        "  df.to_csv(\"top300_rottentomatoes.csv\", index=False)\n",
        "\n",
        "def main():\n",
        "  data = scrape_table()\n",
        "  extracted_data = extract_from_data(data)\n",
        "  dataframe = transform_data(extracted_data)\n",
        "  save_to_csv(dataframe)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "O2yTLSPWnCCf"
      },
      "execution_count": 44,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9+y9lxRk2bQZP54dsyVzl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}